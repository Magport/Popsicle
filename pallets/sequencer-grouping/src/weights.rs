
//! Autogenerated weights for `pallet_sequencer_grouping`
//!
//! THIS FILE WAS AUTO-GENERATED USING THE SUBSTRATE BENCHMARK CLI VERSION 29.0.0
//! DATE: 2024-03-25, STEPS: `50`, REPEAT: `20`, LOW RANGE: `[]`, HIGH RANGE: `[]`
//! WORST CASE MAP SIZE: `1000000`
//! HOSTNAME: `Gerrys-MBP.lan`, CPU: `<UNKNOWN>`
//! WASM-EXECUTION: `Compiled`, CHAIN: `Some("popsicle-dev")`, DB CACHE: 1024

// Executed Command:
// ./target/release/popsicle-node
// benchmark
// pallet
// --chain
// popsicle-dev
// --execution=wasm
// --wasm-execution=compiled
// --pallet
// pallet_sequencer_grouping
// --extrinsic
// *
// --steps
// 50
// --repeat
// 20
// --output
// pallets/sequencer-grouping/src/weights.rs

#![cfg_attr(rustfmt, rustfmt_skip)]
#![allow(unused_parens)]
#![allow(unused_imports)]
#![allow(missing_docs)]

use frame_support::{traits::Get, weights::{Weight, constants::RocksDbWeight}};
use core::marker::PhantomData;

/// Weight functions needed for pallet_sequencer_grouping.
pub trait WeightInfo {
	fn set_group_metric() -> Weight;
	fn benchmark_trigger_group(s: u32, n: u32, ) -> Weight;
}

/// Weights for pallet_template using the Substrate node and recommended hardware.
pub struct SubstrateWeight<T>(PhantomData<T>);
impl<T: frame_system::Config> WeightInfo for SubstrateWeight<T> {
	/// Storage: `SequencerGroupingPallet::GroupSize` (r:0 w:1)
	/// Proof: `SequencerGroupingPallet::GroupSize` (`max_values`: Some(1), `max_size`: Some(4), added: 499, mode: `MaxEncodedLen`)
	/// Storage: `SequencerGroupingPallet::GroupNumber` (r:0 w:1)
	/// Proof: `SequencerGroupingPallet::GroupNumber` (`max_values`: Some(1), `max_size`: Some(4), added: 499, mode: `MaxEncodedLen`)
	fn set_group_metric() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `0`
		//  Estimated: `0`
		// Minimum execution time: 2_000_000 picoseconds.
		Weight::from_parts(3_000_000, 0)
			.saturating_add(Weight::from_parts(0, 0))
			.saturating_add(T::DbWeight::get().writes(2))
	}
	/// Storage: `SequencerGroupingPallet::GroupSize` (r:1 w:0)
	/// Proof: `SequencerGroupingPallet::GroupSize` (`max_values`: Some(1), `max_size`: Some(4), added: 499, mode: `MaxEncodedLen`)
	/// Storage: `SequencerGroupingPallet::GroupNumber` (r:1 w:0)
	/// Proof: `SequencerGroupingPallet::GroupNumber` (`max_values`: Some(1), `max_size`: Some(4), added: 499, mode: `MaxEncodedLen`)
	/// Storage: `System::ParentHash` (r:1 w:0)
	/// Proof: `System::ParentHash` (`max_values`: Some(1), `max_size`: Some(32), added: 527, mode: `MaxEncodedLen`)
	/// Storage: `SequencerGroupingPallet::GroupMembers` (r:0 w:1)
	/// Proof: `SequencerGroupingPallet::GroupMembers` (`max_values`: Some(1), `max_size`: Some(320202), added: 320697, mode: `MaxEncodedLen`)
	/// Storage: `SequencerGroupingPallet::NextRoundStorage` (r:0 w:1)
	/// Proof: `SequencerGroupingPallet::NextRoundStorage` (`max_values`: Some(1), `max_size`: Some(8), added: 503, mode: `MaxEncodedLen`)
	/// The range of component `s` is `[1, 100]`.
	/// The range of component `n` is `[1, 100]`.
	fn benchmark_trigger_group(s: u32, n: u32, ) -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `55`
		//  Estimated: `1517`
		// Minimum execution time: 12_000_000 picoseconds.
		Weight::from_parts(12_000_000, 0)
			.saturating_add(Weight::from_parts(0, 1517))
			// Standard Error: 7_620
			.saturating_add(Weight::from_parts(265_632, 0).saturating_mul(s.into()))
			// Standard Error: 7_620
			.saturating_add(Weight::from_parts(253_149, 0).saturating_mul(n.into()))
			.saturating_add(T::DbWeight::get().reads(3))
			.saturating_add(T::DbWeight::get().writes(2))
	}
}

// For backwards compatibility and tests
impl WeightInfo for () {
	/// Storage: `SequencerGroupingPallet::GroupSize` (r:0 w:1)
	/// Proof: `SequencerGroupingPallet::GroupSize` (`max_values`: Some(1), `max_size`: Some(4), added: 499, mode: `MaxEncodedLen`)
	/// Storage: `SequencerGroupingPallet::GroupNumber` (r:0 w:1)
	/// Proof: `SequencerGroupingPallet::GroupNumber` (`max_values`: Some(1), `max_size`: Some(4), added: 499, mode: `MaxEncodedLen`)
	fn set_group_metric() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `0`
		//  Estimated: `0`
		// Minimum execution time: 2_000_000 picoseconds.
		Weight::from_parts(3_000_000, 0)
			.saturating_add(Weight::from_parts(0, 0))
			.saturating_add(RocksDbWeight::get().writes(2))
	}
	/// Storage: `SequencerGroupingPallet::GroupSize` (r:1 w:0)
	/// Proof: `SequencerGroupingPallet::GroupSize` (`max_values`: Some(1), `max_size`: Some(4), added: 499, mode: `MaxEncodedLen`)
	/// Storage: `SequencerGroupingPallet::GroupNumber` (r:1 w:0)
	/// Proof: `SequencerGroupingPallet::GroupNumber` (`max_values`: Some(1), `max_size`: Some(4), added: 499, mode: `MaxEncodedLen`)
	/// Storage: `System::ParentHash` (r:1 w:0)
	/// Proof: `System::ParentHash` (`max_values`: Some(1), `max_size`: Some(32), added: 527, mode: `MaxEncodedLen`)
	/// Storage: `SequencerGroupingPallet::GroupMembers` (r:0 w:1)
	/// Proof: `SequencerGroupingPallet::GroupMembers` (`max_values`: Some(1), `max_size`: Some(320202), added: 320697, mode: `MaxEncodedLen`)
	/// Storage: `SequencerGroupingPallet::NextRoundStorage` (r:0 w:1)
	/// Proof: `SequencerGroupingPallet::NextRoundStorage` (`max_values`: Some(1), `max_size`: Some(8), added: 503, mode: `MaxEncodedLen`)
	/// The range of component `s` is `[1, 100]`.
	/// The range of component `n` is `[1, 100]`.
	fn benchmark_trigger_group(s: u32, n: u32, ) -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `55`
		//  Estimated: `1517`
		// Minimum execution time: 12_000_000 picoseconds.
		Weight::from_parts(12_000_000, 0)
			.saturating_add(Weight::from_parts(0, 1517))
			// Standard Error: 7_620
			.saturating_add(Weight::from_parts(265_632, 0).saturating_mul(s.into()))
			// Standard Error: 7_620
			.saturating_add(Weight::from_parts(253_149, 0).saturating_mul(n.into()))
			.saturating_add(RocksDbWeight::get().reads(3))
			.saturating_add(RocksDbWeight::get().writes(2))
	}
}
